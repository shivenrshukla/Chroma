# ai/advanced_ai_palette.py
import os
import math
import random
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from itertools import combinations
from image_to_palette import extract_palette as extract_palette_from_image
from torch.utils.data import Dataset, DataLoader
import pandas as pd

# -------------------------- Color conversion utilities --------------------------
def hex_to_rgb(hex_color):
    h = hex_color.strip('#')
    return tuple(int(h[i:i+2], 16) for i in (0, 2, 4))

def rgb_to_xyz(rgb):
    def rgb_to_linear(c):
        c = c / 255.0
        if c <= 0.04045:
            return c / 12.92
        return ((c + 0.055) / 1.055) ** 2.4
    
    r, g, b = [rgb_to_linear(c) for c in rgb]
    x = r * 0.4124564 + g * 0.3575761 + b * 0.1804375
    y = r * 0.2126729 + g * 0.7151522 + b * 0.0721750
    z = r * 0.0193339 + g * 0.1191920 + b * 0.9503041
    return x, y, z

def xyz_to_lab(x, y, z):
    xr, yr, zr = 0.95047, 1.0, 1.08883
    x, y, z = x / xr, y / yr, z / zr
    
    def f(t):
        return t ** (1/3) if t > 0.008856 else 7.787 * t + 16/116
    
    fx, fy, fz = f(x), f(y), f(z)
    L = 116 * fy - 16
    a = 500 * (fx - fy)
    b = 200 * (fy - fz)
    return (L, a, b)

def lab_to_xyz(L, a, b):
    fy = (L + 16) / 116
    fx = a / 500 + fy
    fz = fy - b / 200
    
    def inv_f(t):
        return t ** 3 if t ** 3 > 0.008856 else (t - 16/116) / 7.787
    
    xr, yr, zr = 0.95047, 1.0, 1.08883
    x = inv_f(fx) * xr
    y = inv_f(fy) * yr
    z = inv_f(fz) * zr
    return x, y, z

def xyz_to_rgb(x, y, z):
    r_lin = 3.2404542 * x - 1.5371385 * y - 0.4985314 * z
    g_lin = -0.9692660 * x + 1.8760108 * y + 0.0415560 * z
    b_lin = 0.0556434 * x - 0.2040259 * y + 1.0572252 * z
    
    def to_srgb(u):
        if u <= 0.0031308:
            v = 12.92 * u
        else:
            v = 1.055 * u ** (1/2.4) - 0.055
        return int(round(max(0, min(1, v)) * 255))
    
    return (to_srgb(r_lin), to_srgb(g_lin), to_srgb(b_lin))

def hex_to_lab(h):
    return xyz_to_lab(*rgb_to_xyz(hex_to_rgb(h)))

def lab_to_hex(L, a, b):
    return '#{:02X}{:02X}{:02X}'.format(*xyz_to_rgb(*lab_to_xyz(L, a, b)))

def lab_distance(c1, c2):
    return math.sqrt(sum((c1[i] - c2[i]) ** 2 for i in range(3)))

def palette_hexes_to_lab_array(hex_list):
    return np.array([hex_to_lab(h) for h in hex_list], dtype=np.float32)

# -------------------------- WCAG contrast --------------------------
def relative_luminance(rgb):
    r, g, b = [x / 255.0 for x in rgb]
    
    def f(c): 
        return c / 12.92 if c <= 0.03928 else ((c + 0.055) / 1.055) ** 2.4
    
    r, g, b = f(r), f(g), f(b)
    return 0.2126 * r + 0.7152 * g + 0.0722 * b

def contrast_ratio(hex1, hex2):
    L1 = relative_luminance(hex_to_rgb(hex1))
    L2 = relative_luminance(hex_to_rgb(hex2))
    Lmax, Lmin = max(L1, L2), min(L1, L2)
    return (Lmax + 0.05) / (Lmin + 0.05)

# -------------------------- Scoring Functions --------------------------
def harmony_score(lab_palette):
    ab = lab_palette[:, 1:3]
    angles = np.degrees(np.arctan2(ab[:, 1], ab[:, 0])) % 360
    diffs = []
    K = len(angles)
    for i, j in combinations(range(K), 2):
        d = min(abs(angles[i] - angles[j]), 360 - abs(angles[i] - angles[j]))
        diffs.append(d)
    if not diffs:
        return 0.5
    mean_diff = np.mean(diffs)
    low, high = 20.0, 110.0
    val = (mean_diff - low) / (high - low)
    return float(max(0.0, min(1.0, val)))

def distinctness_score(lab_palette):
    dists = [lab_distance(lab_palette[i], lab_palette[j]) 
             for i, j in combinations(range(len(lab_palette)), 2)]
    mean_d = np.mean(dists) if dists else 0
    val = (mean_d - 6) / (40 - 6)
    return float(max(0.0, min(1.0, val)))

def contrast_score(lab_palette, roles):
    primary_idx = roles.get('primary', [])
    if not primary_idx:
        return 0.5
    
    primary_lab = lab_palette[primary_idx[0]]
    other_indices = roles.get('secondary', []) + roles.get('accent', [])
    if not other_indices:
        return 1.0
    
    scores = []
    for idx in other_indices:
        other_lab = lab_palette[idx]
        # Convert to RGB for contrast calculation
        r1, g1, b1 = xyz_to_rgb(*lab_to_xyz(*primary_lab))
        r2, g2, b2 = xyz_to_rgb(*lab_to_xyz(*other_lab))
        L1 = relative_luminance((r1, g1, b1))
        L2 = relative_luminance((r2, g2, b2))
        ratio = (max(L1, L2) + 0.05) / (min(L1, L2) + 0.05)
        score = 1 / (1 + math.exp(-1.5 * (ratio - 4.5)))
        scores.append(score)
    
    return float(np.mean(scores))

def cohesion_score(lab_palette):
    ab = lab_palette[:, 1:3]
    from sklearn.metrics import pairwise_distances
    dists = pairwise_distances(ab)
    mean_dist = np.mean(dists)
    return float(np.exp(-mean_dist / 20))

def weight_score(lab_palette, roles):
    total = len(lab_palette)
    ratios = {'primary': 0.6, 'secondary': 0.25, 'accent': 0.15}
    score = 0.0
    for role in ratios:
        obs = len(roles.get(role, [])) / total
        score += max(0, 1 - abs(obs - ratios[role]))
    return float(score / 3)

# -------------------------- Model Definition --------------------------
class PaletteAestheticNet(nn.Module):
    def __init__(self, K=8, hidden_dim=128):
        super().__init__()
        self.K = K
        self.input_dim = K * 3
        self.fc1 = nn.Linear(self.input_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, hidden_dim)
        self.out = nn.Linear(hidden_dim, 1)

    def forward(self, palette_lab):
        x = palette_lab.view(palette_lab.size(0), self.K * 3)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = torch.sigmoid(self.out(x))
        return x.squeeze(1)

# -------------------------- Role Assignment --------------------------
def assign_roles(hex_palette):
    lab = palette_hexes_to_lab_array(hex_palette)
    K = len(hex_palette)
    sat = np.linalg.norm(lab[:, 1:3], axis=1)
    L = lab[:, 0]
    
    idx_primary = [int(np.argmax(sat))]
    remaining = [i for i in range(K) if i not in idx_primary]
    
    if remaining:
        dists = [lab_distance(lab[i], lab[idx_primary[0]]) for i in remaining]
        idx_secondary = sorted(remaining, key=lambda i: -dists[i % len(dists)])[:2]
    else:
        idx_secondary = []
    
    remaining = [i for i in range(K) if i not in idx_primary + idx_secondary]
    idx_accent = sorted(remaining, key=lambda i: -sat[i])[:2] if remaining else []
    
    return {
        'primary': idx_primary,
        'secondary': idx_secondary,
        'accent': idx_accent
    }

# -------------------------- Composite Reward --------------------------
def composite_reward(hex_palette, roles, weights=None, model_L=None, k_value=8):
    if len(hex_palette) < k_value:
        # Pad with white if the palette is too short
        padding = ["#FFFFFF"] * (k_value - len(hex_palette))
        hex_palette.extend(padding)
    elif len(hex_palette) > k_value:
        # Truncate if the palette is too long
        hex_palette = hex_palette[:k_value]

    lab_palette = palette_hexes_to_lab_array(hex_palette)
    
    H = harmony_score(lab_palette)
    D = distinctness_score(lab_palette)
    P = cohesion_score(lab_palette)
    W = weight_score(lab_palette, roles)
    C = contrast_score(lab_palette, roles)
    
    # Learned aesthetic score
    L = 0.5                     # Default
    if model_L is None:
        model_L = train_model_aadb()
        
    try:
        model_L.eval()
        pal = torch.from_numpy(lab_palette.astype(np.float32)).unsqueeze(0)
        with torch.no_grad():
            L = float(model_L(pal).item())
            L = max(0.0, min(1.0, L))
    except Exception as e:
        print(f"Error using model_L: {e}")
        L = 0.5
    
    if weights is None:
        weights = {'H': 0.25, 'C': 0.25, 'D': 0.2, 'W': 0.1, 'P': 0.1, 'L': 0.1}
    
    reward = (weights['H'] * H + weights['C'] * C + weights['D'] * D + 
              weights['W'] * W + weights['P'] * P + weights['L'] * L)
    
    components = {'H': H, 'C': C, 'D': D, 'W': W, 'P': P, 'L': L}
    return float(reward), components

# -------------------------- Simple Optimization --------------------------
def optimize_palette(init_hex, steps=100, episodes_per_step=4, lr=1e-3, 
                    seed=42, model_L=None, **kwargs):
    # Simplified palette optimization using random search with gradient-like improvements
    random.seed(seed)
    np.random.seed(seed)
    
    K = len(init_hex)
    best_palette = init_hex.copy()
    best_roles = assign_roles(best_palette)
    best_score, best_components = composite_reward(best_palette, best_roles, model_L=model_L)
    
    for step in range(steps):
        for episode in range(episodes_per_step):
            # Create a variation of current best palette
            candidate_palette = []
            for hex_color in best_palette:
                lab = hex_to_lab(hex_color)
                # Add small random variations
                noise_L = random.gauss(0, 5)
                noise_a = random.gauss(0, 10)
                noise_b = random.gauss(0, 10)
                
                new_lab = (
                    max(0, min(100, lab[0] + noise_L)),
                    max(-128, min(127, lab[1] + noise_a)),
                    max(-128, min(127, lab[2] + noise_b))
                )
                
                try:
                    new_hex = lab_to_hex(*new_lab)
                    candidate_palette.append(new_hex)
                except:
                    candidate_palette.append(hex_color)  # Keep original if conversion fails
            
            # Evaluate candidate
            candidate_roles = assign_roles(candidate_palette)
            candidate_score, candidate_components = composite_reward(
                candidate_palette, candidate_roles, model_L=model_L
            )
            
            # Update if better
            if candidate_score > best_score:
                best_palette = candidate_palette
                best_roles = candidate_roles
                best_score = candidate_score
                best_components = candidate_components
    
    return best_palette, best_roles, best_score, best_components

# -------------------------- Training Function --------------------------
# 1. Load AADB metadata
def load_aadb_metadata(aadb_csv_path, images_dir):
    """
    Load AADB CSV metadata and normalize scores.
    Automatically matches images case-insensitively.
    """
    df = pd.read_csv(aadb_csv_path)

    if 'score' not in df.columns:
        raise ValueError("Cannot find 'score' column in CSV")
    raw_scores = df['score']

    # Normalize scores to [0,1]
    df['score_norm'] = (raw_scores - raw_scores.min()) / (raw_scores.max() - raw_scores.min())

    if 'ImageFile' not in df.columns:
        raise ValueError("Cannot find 'ImageFile' column in CSV")

    # Build a dict of lower-case filename -> actual file path in folder
    all_files = {f.lower(): os.path.join(images_dir, f) for f in os.listdir(images_dir)}

    # Map CSV filenames to actual files
    df['image_path'] = df['ImageFile'].apply(lambda fn: all_files.get(fn.lower(), None))

    missing = df[df['image_path'].isnull()]
    if len(missing) > 0:
        print(f"Warning: {len(missing)} images not found. Examples:\n", missing.head())

    df = df[df['image_path'].notnull()].reset_index(drop=True)
    return df[['image_path', 'score_norm']]

# 3. Dataset class
class AADBBasedPaletteDataset(Dataset):
    def __init__(self, metadata_df, K=5, transform=None):
        self.metadata = metadata_df
        self.K = K
        self.transform = transform

    def __len__(self):
        return len(self.metadata)

    def __getitem__(self, idx):
        row = self.metadata.iloc[idx]
        img_path = row['image_path']
        score = row['score_norm']
        try:
            palette = extract_palette_from_image(img_path, K=self.K)
        except Exception as e:
            # if image read fails, fallback
            palette = np.zeros((self.K,3), dtype=np.float32)
        return palette.astype(np.float32), np.float32(score)

def train_model_aadb(aadb_csv, aadb_images_dir, K=8,
                     batch_size=32, epochs=15, lr=1e-3, val_frac=0.1):
    """
    Train PaletteAestheticNet on AADB dataset.
    """
    # Load metadata
    df = load_aadb_metadata(aadb_csv, aadb_images_dir)
    if len(df) == 0:
        raise ValueError("No images found. Check CSV and image folder paths.")

    # Split into train/val
    n_val = int(len(df) * val_frac)
    df_train = df.sample(n=len(df)-n_val, random_state=42).reset_index(drop=True)
    df_val   = df.drop(df_train.index).reset_index(drop=True)

    # Create datasets
    train_ds = AADBBasedPaletteDataset(df_train, K=K)
    val_ds   = AADBBasedPaletteDataset(df_val, K=K)

    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)
    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)

    # Device
    device = "mps" if torch.backends.mps.is_available() else "cpu"

    # Model
    model = PaletteAestheticNet(K=K, hidden_dim=128).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    loss_fn = nn.MSELoss()

    # Training loop
    for epoch in range(epochs):
        model.train()
        train_losses = []
        for palettes, scores in train_loader:
            palettes = palettes.to(device)
            scores = scores.to(device)
            preds = model(palettes)
            loss = loss_fn(preds, scores)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            train_losses.append(loss.item())

        # Validation
        model.eval()
        val_losses = []
        with torch.no_grad():
            for palettes, scores in val_loader:
                palettes = palettes.to(device)
                scores = scores.to(device)
                preds = model(palettes)
                loss = loss_fn(preds, scores)
                val_losses.append(loss.item())

        print(f"Epoch {epoch+1}/{epochs}, "
              f"train_loss={np.mean(train_losses):.4f}, "
              f"val_loss={np.mean(val_losses):.4f}")

    return model

if __name__ == "__main__":
    # Test the module
    test_palette = ["#FF6F61", "#FFD662", "#6B5B95", "#88B04B", "#F7CAC9"]
    roles = assign_roles(test_palette)
    score, components = composite_reward(test_palette, roles)
    print(f"Test palette score: {score:.4f}")
    print(f"Components: {components}")